{
  "model": "llama3.2:1b",
  "temperature": 0.5,
  "num_predict": 300,
  "num_ctx": 4096,
  "context_length": 1000,
  "top_k": 10,
  "top_p": 0.5,
  "repeat_penalty": 1.1
}